{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ECG CNN Training\n",
        "\n",
        "This notebook implements an advanced 1D CNN for ECG age group classification with the following features:\n",
        "\n",
        "- **Class imbalance handling**: Focal loss, class weighting, data augmentation\n",
        "- **Advanced architecture**: ResNet blocks, attention mechanisms\n",
        "- **Comprehensive regularization**: Dropout, batch normalization, gradient clipping\n",
        "- **Direct WFDB parsing**: From .dat/.hea files\n",
        "\n",
        "## Table of Contents\n",
        "1. [Data Loading](#data-loading)\n",
        "2. [Data Preprocessing](#data-preprocessing)\n",
        "3. [Model Architecture](#model-architecture)\n",
        "4. [Hyperparameter Configuration](#hyperparameter-configuration)\n",
        "5. [Model Training](#model-training)\n",
        "6. [Model Evaluation](#model-evaluation)\n",
        "7. [Visualization and Analysis](#visualization-and-analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading\n",
        "\n",
        "Load ECG data using the WFDB parser with advanced preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n",
            "M4 Pro GPU optimizations enabled\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler, Subset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import random\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "# Add parent directory to path to import wfdb_parser\n",
        "sys.path.append('..')\n",
        "from wfdb_parser import create_wfdb_dataset\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "DATA_PATH = \"../input/autonomic-aging-a-dataset-to-quantify-changes-of-cardiovascular-autonomic-function-during-healthy-aging-1.0.0\"\n",
        "SUBJECT_INFO_CSV = \"../input/autonomic-aging-a-dataset-to-quantify-changes-of-cardiovascular-autonomic-function-during-healthy-aging-1.0.0/subject-info.csv\"\n",
        "OUTPUT_DIR = \"./ecg_cnn_outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Dataset parameters\n",
        "WINDOW_SIZE_SEC = 10\n",
        "WINDOW_STEP_SEC = 5\n",
        "PRELOAD_DATA = True  # Optimized for 16GB RAM\n",
        "\n",
        "# Training parameters\n",
        "RANDOM_STATE = 42\n",
        "TEST_SPLIT = 0.2\n",
        "BATCH_SIZE = 128  # Optimized for M4 Pro GPU\n",
        "EPOCHS = 50\n",
        "LR = 1e-3\n",
        "\n",
        "# Device detection with M4 Pro GPU support\n",
        "def get_device():\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")  # M4 Pro GPU\n",
        "    elif torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")  # NVIDIA GPU\n",
        "    else:\n",
        "        return torch.device(\"cpu\")  # CPU fallback\n",
        "\n",
        "DEVICE = get_device()\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# M4 Pro GPU optimizations\n",
        "if DEVICE.type == \"mps\":\n",
        "    torch.backends.mps.allow_tf32 = True\n",
        "    torch.backends.mps.allow_fp16 = True\n",
        "    print(\"M4 Pro GPU optimizations enabled\")\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from WFDB files...\n",
            "Error processing record 0400: [Errno 2] No such file or directory: '/Users/dmytro/Diploma/ecg_ml_analysis/v2/input/autonomic-aging-a-dataset-to-quantify-changes-of-cardiovascular-autonomic-function-during-healthy-aging-1.0.0/0400.dat'\n",
            "Preloading data...\n",
            "Preloaded 0/234943 samples\n",
            "Preloaded 1000/234943 samples\n",
            "Preloaded 2000/234943 samples\n",
            "Preloaded 3000/234943 samples\n",
            "Preloaded 4000/234943 samples\n",
            "Preloaded 5000/234943 samples\n",
            "Preloaded 6000/234943 samples\n",
            "Preloaded 7000/234943 samples\n",
            "Preloaded 8000/234943 samples\n",
            "Preloaded 9000/234943 samples\n",
            "Preloaded 10000/234943 samples\n",
            "Preloaded 11000/234943 samples\n",
            "Preloaded 12000/234943 samples\n",
            "Preloaded 13000/234943 samples\n",
            "Preloaded 14000/234943 samples\n",
            "Preloaded 15000/234943 samples\n",
            "Preloaded 16000/234943 samples\n",
            "Preloaded 17000/234943 samples\n",
            "Preloaded 18000/234943 samples\n",
            "Preloaded 19000/234943 samples\n",
            "Preloaded 20000/234943 samples\n",
            "Preloaded 21000/234943 samples\n",
            "Preloaded 22000/234943 samples\n",
            "Preloaded 23000/234943 samples\n",
            "Preloaded 24000/234943 samples\n",
            "Preloaded 25000/234943 samples\n",
            "Preloaded 26000/234943 samples\n",
            "Preloaded 27000/234943 samples\n",
            "Preloaded 28000/234943 samples\n",
            "Preloaded 29000/234943 samples\n",
            "Preloaded 30000/234943 samples\n",
            "Preloaded 31000/234943 samples\n",
            "Preloaded 32000/234943 samples\n",
            "Preloaded 33000/234943 samples\n",
            "Preloaded 34000/234943 samples\n",
            "Preloaded 35000/234943 samples\n",
            "Preloaded 36000/234943 samples\n",
            "Preloaded 37000/234943 samples\n",
            "Preloaded 38000/234943 samples\n",
            "Preloaded 39000/234943 samples\n",
            "Preloaded 40000/234943 samples\n",
            "Preloaded 41000/234943 samples\n",
            "Preloaded 42000/234943 samples\n",
            "Preloaded 43000/234943 samples\n",
            "Preloaded 44000/234943 samples\n",
            "Preloaded 45000/234943 samples\n",
            "Preloaded 46000/234943 samples\n",
            "Preloaded 47000/234943 samples\n",
            "Preloaded 48000/234943 samples\n",
            "Preloaded 49000/234943 samples\n",
            "Preloaded 50000/234943 samples\n",
            "Preloaded 51000/234943 samples\n",
            "Preloaded 52000/234943 samples\n",
            "Preloaded 53000/234943 samples\n",
            "Preloaded 54000/234943 samples\n",
            "Preloaded 55000/234943 samples\n",
            "Preloaded 56000/234943 samples\n",
            "Preloaded 57000/234943 samples\n",
            "Preloaded 58000/234943 samples\n",
            "Preloaded 59000/234943 samples\n",
            "Preloaded 60000/234943 samples\n",
            "Preloaded 61000/234943 samples\n",
            "Preloaded 62000/234943 samples\n",
            "Preloaded 63000/234943 samples\n",
            "Preloaded 64000/234943 samples\n",
            "Preloaded 65000/234943 samples\n",
            "Preloaded 66000/234943 samples\n",
            "Preloaded 67000/234943 samples\n",
            "Preloaded 68000/234943 samples\n",
            "Preloaded 69000/234943 samples\n",
            "Preloaded 70000/234943 samples\n",
            "Preloaded 71000/234943 samples\n",
            "Preloaded 72000/234943 samples\n",
            "Preloaded 73000/234943 samples\n",
            "Preloaded 74000/234943 samples\n",
            "Preloaded 75000/234943 samples\n",
            "Preloaded 76000/234943 samples\n",
            "Preloaded 77000/234943 samples\n",
            "Preloaded 78000/234943 samples\n",
            "Preloaded 79000/234943 samples\n",
            "Preloaded 80000/234943 samples\n",
            "Preloaded 81000/234943 samples\n",
            "Preloaded 82000/234943 samples\n",
            "Preloaded 83000/234943 samples\n",
            "Preloaded 84000/234943 samples\n",
            "Preloaded 85000/234943 samples\n",
            "Preloaded 86000/234943 samples\n",
            "Preloaded 87000/234943 samples\n",
            "Preloaded 88000/234943 samples\n",
            "Preloaded 89000/234943 samples\n",
            "Preloaded 90000/234943 samples\n",
            "Preloaded 91000/234943 samples\n",
            "Preloaded 92000/234943 samples\n",
            "Preloaded 93000/234943 samples\n",
            "Preloaded 94000/234943 samples\n",
            "Preloaded 95000/234943 samples\n",
            "Preloaded 96000/234943 samples\n",
            "Preloaded 97000/234943 samples\n",
            "Preloaded 98000/234943 samples\n",
            "Preloaded 99000/234943 samples\n",
            "Preloaded 100000/234943 samples\n",
            "Preloaded 101000/234943 samples\n",
            "Preloaded 102000/234943 samples\n",
            "Preloaded 103000/234943 samples\n",
            "Preloaded 104000/234943 samples\n",
            "Preloaded 105000/234943 samples\n",
            "Preloaded 106000/234943 samples\n",
            "Preloaded 107000/234943 samples\n",
            "Preloaded 108000/234943 samples\n",
            "Preloaded 109000/234943 samples\n",
            "Preloaded 110000/234943 samples\n",
            "Preloaded 111000/234943 samples\n",
            "Preloaded 112000/234943 samples\n",
            "Preloaded 113000/234943 samples\n",
            "Preloaded 114000/234943 samples\n",
            "Preloaded 115000/234943 samples\n",
            "Preloaded 116000/234943 samples\n",
            "Preloaded 117000/234943 samples\n",
            "Preloaded 118000/234943 samples\n",
            "Preloaded 119000/234943 samples\n",
            "Preloaded 120000/234943 samples\n",
            "Preloaded 121000/234943 samples\n",
            "Preloaded 122000/234943 samples\n",
            "Preloaded 123000/234943 samples\n",
            "Preloaded 124000/234943 samples\n",
            "Preloaded 125000/234943 samples\n",
            "Preloaded 126000/234943 samples\n",
            "Preloaded 127000/234943 samples\n",
            "Preloaded 128000/234943 samples\n",
            "Preloaded 129000/234943 samples\n",
            "Preloaded 130000/234943 samples\n",
            "Preloaded 131000/234943 samples\n",
            "Preloaded 132000/234943 samples\n",
            "Preloaded 133000/234943 samples\n",
            "Preloaded 134000/234943 samples\n",
            "Preloaded 135000/234943 samples\n",
            "Preloaded 136000/234943 samples\n",
            "Preloaded 137000/234943 samples\n",
            "Preloaded 138000/234943 samples\n",
            "Preloaded 139000/234943 samples\n",
            "Preloaded 140000/234943 samples\n",
            "Preloaded 141000/234943 samples\n",
            "Preloaded 142000/234943 samples\n",
            "Preloaded 143000/234943 samples\n",
            "Preloaded 144000/234943 samples\n",
            "Preloaded 145000/234943 samples\n",
            "Preloaded 146000/234943 samples\n",
            "Preloaded 147000/234943 samples\n",
            "Preloaded 148000/234943 samples\n",
            "Preloaded 149000/234943 samples\n",
            "Preloaded 150000/234943 samples\n",
            "Preloaded 151000/234943 samples\n",
            "Preloaded 152000/234943 samples\n",
            "Preloaded 153000/234943 samples\n",
            "Preloaded 154000/234943 samples\n",
            "Preloaded 155000/234943 samples\n",
            "Preloaded 156000/234943 samples\n",
            "Preloaded 157000/234943 samples\n",
            "Preloaded 158000/234943 samples\n",
            "Preloaded 159000/234943 samples\n",
            "Preloaded 160000/234943 samples\n",
            "Preloaded 161000/234943 samples\n",
            "Preloaded 162000/234943 samples\n",
            "Preloaded 163000/234943 samples\n",
            "Preloaded 164000/234943 samples\n",
            "Preloaded 165000/234943 samples\n",
            "Preloaded 166000/234943 samples\n",
            "Preloaded 167000/234943 samples\n",
            "Preloaded 168000/234943 samples\n",
            "Preloaded 169000/234943 samples\n",
            "Preloaded 170000/234943 samples\n",
            "Preloaded 171000/234943 samples\n",
            "Preloaded 172000/234943 samples\n",
            "Preloaded 173000/234943 samples\n",
            "Preloaded 174000/234943 samples\n",
            "Preloaded 175000/234943 samples\n",
            "Preloaded 176000/234943 samples\n",
            "Preloaded 177000/234943 samples\n",
            "Preloaded 178000/234943 samples\n",
            "Preloaded 179000/234943 samples\n",
            "Preloaded 180000/234943 samples\n",
            "Preloaded 181000/234943 samples\n",
            "Preloaded 182000/234943 samples\n",
            "Preloaded 183000/234943 samples\n",
            "Preloaded 184000/234943 samples\n",
            "Preloaded 185000/234943 samples\n",
            "Preloaded 186000/234943 samples\n",
            "Preloaded 187000/234943 samples\n",
            "Preloaded 188000/234943 samples\n",
            "Preloaded 189000/234943 samples\n",
            "Preloaded 190000/234943 samples\n",
            "Preloaded 191000/234943 samples\n",
            "Preloaded 192000/234943 samples\n",
            "Preloaded 193000/234943 samples\n",
            "Preloaded 194000/234943 samples\n",
            "Preloaded 195000/234943 samples\n",
            "Preloaded 196000/234943 samples\n",
            "Preloaded 197000/234943 samples\n",
            "Preloaded 198000/234943 samples\n",
            "Preloaded 199000/234943 samples\n",
            "Preloaded 200000/234943 samples\n",
            "Preloaded 201000/234943 samples\n",
            "Preloaded 202000/234943 samples\n",
            "Preloaded 203000/234943 samples\n",
            "Preloaded 204000/234943 samples\n",
            "Preloaded 205000/234943 samples\n",
            "Preloaded 206000/234943 samples\n",
            "Preloaded 207000/234943 samples\n",
            "Preloaded 208000/234943 samples\n",
            "Preloaded 209000/234943 samples\n",
            "Preloaded 210000/234943 samples\n",
            "Preloaded 211000/234943 samples\n",
            "Preloaded 212000/234943 samples\n",
            "Preloaded 213000/234943 samples\n",
            "Preloaded 214000/234943 samples\n",
            "Preloaded 215000/234943 samples\n",
            "Preloaded 216000/234943 samples\n",
            "Preloaded 217000/234943 samples\n",
            "Preloaded 218000/234943 samples\n",
            "Preloaded 219000/234943 samples\n",
            "Preloaded 220000/234943 samples\n",
            "Preloaded 221000/234943 samples\n",
            "Preloaded 222000/234943 samples\n",
            "Preloaded 223000/234943 samples\n",
            "Preloaded 224000/234943 samples\n",
            "Preloaded 225000/234943 samples\n",
            "Preloaded 226000/234943 samples\n",
            "Preloaded 227000/234943 samples\n",
            "Preloaded 228000/234943 samples\n",
            "Preloaded 229000/234943 samples\n",
            "Preloaded 230000/234943 samples\n",
            "Preloaded 231000/234943 samples\n",
            "Preloaded 232000/234943 samples\n",
            "Preloaded 233000/234943 samples\n",
            "Preloaded 234000/234943 samples\n",
            "--- LEAKAGE CHECK ---\n",
            "Unique records in Train: 876\n",
            "Unique records in Test: 219\n",
            "Overlapping records (MUST BE 0): 0\n",
            "SUCCESS: Data split is clean based on Record ID.\n",
            "---------------------\n",
            "Number of classes: 15, Channels: 3\n",
            "Train samples: 187591, Test samples: 47352\n",
            "Augmented train samples: 187591\n",
            "Class distribution: Counter({np.float64(2.0): 87555, np.float64(3.0): 49820, np.float64(4.0): 22515, np.float64(7.0): 11694, np.float64(6.0): 11474, np.float64(1.0): 11248, np.float64(8.0): 10842, np.float64(5.0): 10506, np.float64(10.0): 5329, np.float64(11.0): 3689, np.float64(9.0): 3483, np.float64(12.0): 2328, np.float64(14.0): 2038, np.float64(15.0): 1253, np.float64(13.0): 1169})\n",
            "Dataset total samples: 234943\n",
            "Train indices range: 0 to 234759\n",
            "Test indices range: 565 to 234942\n"
          ]
        }
      ],
      "source": [
        "# Load dataset from WFDB files\n",
        "print(\"Loading dataset from WFDB files...\")\n",
        "dataset = create_wfdb_dataset(\n",
        "    data_path=DATA_PATH,\n",
        "    subject_info_csv=SUBJECT_INFO_CSV,\n",
        "    window_size_sec=WINDOW_SIZE_SEC,\n",
        "    window_step_sec=WINDOW_STEP_SEC,\n",
        "    augment=False,  # We'll handle augmentation in the training loop\n",
        "    preload=PRELOAD_DATA\n",
        ")\n",
        "\n",
        "# Train/test split\n",
        "groups = [sample['record_name'] for sample in dataset.samples]\n",
        "\n",
        "# 2. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ GroupShuffleSplit –∑–∞–º—ñ—Å—Ç—å random_split\n",
        "# –¶–µ –≥–∞—Ä–∞–Ω—Ç—É—î, —â–æ –≤—Å—ñ –≤—ñ–∫–Ω–∞ –∑ –æ–¥–Ω–æ–≥–æ record_name –ø–æ—Ç—Ä–∞–ø–ª—è—Ç—å –ê–ë–û –≤ train, –ê–ë–û –≤ test\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SPLIT, random_state=42)\n",
        "train_idx, test_idx = next(gss.split(X=range(len(dataset)), groups=groups))\n",
        "\n",
        "# 3. –°—Ç–≤–æ—Ä—é—î–º–æ –ø—ñ–¥–º–Ω–æ–∂–∏–Ω–∏ (Subsets) –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –æ—Ç—Ä–∏–º–∞–Ω—ñ —ñ–Ω–¥–µ–∫—Å–∏\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ \"—á–µ—Å–Ω—ñ—Å—Ç—å\" –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É (Leakage Check)\n",
        "train_patients = set(np.array(groups)[train_idx])\n",
        "test_patients = set(np.array(groups)[test_idx])\n",
        "intersection = train_patients.intersection(test_patients)\n",
        "\n",
        "print(f\"--- LEAKAGE CHECK ---\")\n",
        "print(f\"Unique records in Train: {len(train_patients)}\")\n",
        "print(f\"Unique records in Test: {len(test_patients)}\")\n",
        "print(f\"Overlapping records (MUST BE 0): {len(intersection)}\")\n",
        "if len(intersection) > 0:\n",
        "    raise ValueError(\"CRITICAL ERROR: Data leakage detected! Same patient in Train and Test.\")\n",
        "else:\n",
        "    print(\"SUCCESS: Data split is clean based on Record ID.\")\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Create a wrapper for the training dataset that enables augmentation\n",
        "class AugmentedDataset:\n",
        "    def __init__(self, base_dataset, indices):\n",
        "        self.base_dataset = base_dataset\n",
        "        self.indices = indices\n",
        "        # Enable augmentation for this dataset\n",
        "        self.base_dataset.augment = True\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.base_dataset[self.indices[idx]]\n",
        "\n",
        "# Create augmented training dataset\n",
        "train_dataset_aug = AugmentedDataset(dataset, train_dataset.indices)\n",
        "\n",
        "n_classes = len(dataset.classes_)\n",
        "n_channels = dataset.max_channels\n",
        "print(f\"Number of classes: {n_classes}, Channels: {n_channels}\")\n",
        "print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "print(f\"Augmented train samples: {len(train_dataset_aug)}\")\n",
        "print(f\"Class distribution: {dataset.get_class_distribution()}\")\n",
        "\n",
        "# Debug: Check if indices are valid\n",
        "print(f\"Dataset total samples: {len(dataset)}\")\n",
        "print(f\"Train indices range: {min(train_dataset.indices)} to {max(train_dataset.indices)}\")\n",
        "print(f\"Test indices range: {min(test_dataset.indices)} to {max(test_dataset.indices)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing\n",
        "\n",
        "Handle class imbalance and create weighted sampling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution: {np.int64(1): 87555, np.int64(6): 11694, np.int64(3): 22515, np.int64(2): 49820, np.int64(0): 11248, np.int64(8): 3483, np.int64(7): 10842, np.int64(11): 2328, np.int64(4): 10506, np.int64(9): 5329, np.int64(10): 3689, np.int64(5): 11474, np.int64(12): 1169, np.int64(14): 1253, np.int64(13): 2038}\n",
            "Class weights: tensor([ 1.3925,  0.1789,  0.3144,  0.6957,  1.4908,  1.3651,  1.3394,  1.4446,\n",
            "         4.4969,  2.9392,  4.2458,  6.7280, 13.3985,  7.6854, 12.5003],\n",
            "       device='mps:0')\n",
            "‚úÖ Data preprocessing completed\n",
            "  ‚Ä¢ Training samples: 187591\n",
            "  ‚Ä¢ Test samples: 47352\n",
            "  ‚Ä¢ Class weights computed: 15 classes\n"
          ]
        }
      ],
      "source": [
        "# Compute class weights for handling imbalance\n",
        "# Get class distribution for weighting\n",
        "all_labels = []\n",
        "for sample in dataset.samples:\n",
        "    all_labels.append(dataset.le.transform([sample['age_group']])[0])\n",
        "\n",
        "class_counts = Counter(all_labels)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(all_labels), y=all_labels)\n",
        "class_weights = torch.FloatTensor(class_weights).to(DEVICE)\n",
        "\n",
        "print(f\"Class distribution: {dict(class_counts)}\")\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Use weighted sampler for training (only for training indices)\n",
        "train_labels = [all_labels[i] for i in train_dataset.indices]\n",
        "sample_weights = [class_weights[label] for label in train_labels]\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "# Create data loaders (use num_workers=0 to avoid multiprocessing issues on macOS)\n",
        "train_loader = DataLoader(train_dataset_aug, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"‚úÖ Data preprocessing completed\")\n",
        "print(f\"  ‚Ä¢ Training samples: {len(train_dataset_aug)}\")\n",
        "print(f\"  ‚Ä¢ Test samples: {len(test_dataset)}\")\n",
        "print(f\"  ‚Ä¢ Class weights computed: {len(class_weights)} classes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Architecture\n",
        "\n",
        "Define the advanced CNN architecture with ResNet blocks and attention mechanisms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Advanced CNN architecture defined\n"
          ]
        }
      ],
      "source": [
        "# Advanced CNN Architecture Components\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dropout_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding=kernel_size//2)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        \n",
        "        # Spatial Dropout (Dropout1d) –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à–∏–π –¥–ª—è —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤\n",
        "        self.dropout = nn.Dropout1d(p=dropout_prob)\n",
        "        \n",
        "        # Skip connection\n",
        "        self.skip = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.skip = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, 1, stride),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = self.skip(x)\n",
        "        \n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.dropout(out) # Dropout –ø—ñ—Å–ª—è –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            nn.Conv1d(channels, channels//4, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        att = self.attention(x)\n",
        "        return x * att\n",
        "\n",
        "class AdvancedCNN1D(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 2. –ó–º–µ–Ω—à—É—î–º–æ –ø–æ—á–∞—Ç–∫–æ–≤—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ (Model Thinning)\n",
        "        # –ë—É–ª–æ 64, —Å—Ç–∞–ª–æ 32. –¶–µ –∑–º–µ–Ω—à–∏—Ç—å –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤.\n",
        "        base_filters = 32 \n",
        "        \n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, base_filters, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(base_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "        \n",
        "        # Stage 1\n",
        "        self.res_block1 = ResidualBlock(base_filters, base_filters, dropout_prob=0.2)\n",
        "        self.attention1 = AttentionBlock(base_filters)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        \n",
        "        # Stage 2 (Filters: 32 -> 64)\n",
        "        self.res_block2 = ResidualBlock(base_filters, base_filters*2, stride=2, dropout_prob=0.3)\n",
        "        self.attention2 = AttentionBlock(base_filters*2)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        \n",
        "        # Stage 3 (Filters: 64 -> 128) - –ú–∞–∫—Å–∏–º—É–º 128 –∫–∞–Ω–∞–ª—ñ–≤ –∑–∞–º—ñ—Å—Ç—å 256\n",
        "        self.res_block3 = ResidualBlock(base_filters*2, base_filters*4, stride=2, dropout_prob=0.4)\n",
        "        self.attention3 = AttentionBlock(base_filters*4)\n",
        "        self.pool3 = nn.MaxPool1d(2)\n",
        "        \n",
        "        # Global pooling and classification\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        \n",
        "        # –§—ñ–Ω–∞–ª—å–Ω–∏–π Dropout –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 0.6\n",
        "        self.dropout = nn.Dropout(0.6) \n",
        "        self.fc = nn.Linear(base_filters*4, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        \n",
        "        x = self.res_block1(x)\n",
        "        x = self.attention1(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.res_block2(x)\n",
        "        x = self.attention2(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = self.res_block3(x)\n",
        "        x = self.attention3(x)\n",
        "        x = self.pool3(x)\n",
        "        \n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "print(\"‚úÖ Advanced CNN architecture defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Hyperparameter Configuration\n",
        "\n",
        "Set up loss functions, optimizer, and training parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Hyperparameter Configuration:\n",
            "  ‚Ä¢ Model: Advanced CNN with ResNet blocks\n",
            "  ‚Ä¢ Loss function: Focal Loss (alpha=1, gamma=2)\n",
            "  ‚Ä¢ Optimizer: AdamW (lr=0.001, weight_decay=1e-4)\n",
            "  ‚Ä¢ Scheduler: ReduceLROnPlateau\n",
            "  ‚Ä¢ Batch size: 128\n",
            "  ‚Ä¢ Epochs: 50\n",
            "  ‚Ä¢ Classes: 15\n",
            "  ‚Ä¢ Channels: 3\n",
            "  ‚Ä¢ Total parameters: 486,975\n",
            "  ‚Ä¢ Model size: 1.86 MB\n"
          ]
        }
      ],
      "source": [
        "# Focal Loss for handling class imbalance\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    \n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        \n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "# Initialize model\n",
        "model = AdvancedCNN1D(n_channels, n_classes).to(DEVICE)\n",
        "\n",
        "# 3. –ê–≥—Ä–µ—Å–∏–≤–Ω–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –≤ –æ–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä—ñ\n",
        "# Weight Decay –∑–±—ñ–ª—å—à–µ–Ω–æ –∑ 1e-4 –¥–æ 0.01 (–∞–±–æ 1e-2)\n",
        "# –¶–µ –∑–º—É—à—É—î –≤–∞–≥–∏ –∑–∞–ª–∏—à–∞—Ç–∏—Å—è –º–∞–ª–∏–º–∏, —â–æ –∑–º–µ–Ω—à—É—î –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "\n",
        "# Scheduler –∑–∞–ª–∏—à–∞—î–º–æ, –∞–ª–µ –º–æ–∂–Ω–∞ –∑–±—ñ–ª—å—à–∏—Ç–∏ patience\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
        "\n",
        "criterion = FocalLoss(alpha=1, gamma=2)\n",
        "\n",
        "print(\"üìã Hyperparameter Configuration:\")\n",
        "print(f\"  ‚Ä¢ Model: Advanced CNN with ResNet blocks\")\n",
        "print(f\"  ‚Ä¢ Regularization: Spatial Dropout inside blocks + High Weight Decay\")\n",
        "print(f\"  ‚Ä¢ Loss function: Focal Loss (alpha=1, gamma=2)\")\n",
        "print(f\"  ‚Ä¢ Optimizer: AdamW (lr={LR}, weight_decay=0.01)\")\n",
        "print(f\"  ‚Ä¢ Scheduler: ReduceLROnPlateau\")\n",
        "print(f\"  ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  ‚Ä¢ Epochs: {EPOCHS}\")\n",
        "print(f\"  ‚Ä¢ Classes: {n_classes}\")\n",
        "print(f\"  ‚Ä¢ Channels: {n_channels}\")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"  ‚Ä¢ Total parameters: {total_params:,}\")\n",
        "print(f\"  ‚Ä¢ Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training\n",
        "\n",
        "Train the CNN with advanced techniques including early stopping and gradient clipping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ Training for 50 epochs...\n",
            "Training epoch 1/50\n",
            "M4 Pro GPU memory allocated: 0.00 GB\n",
            "Epoch 1/50 | Train Acc: 0.592 | Val Acc: 0.221 | Best: 0.221\n",
            "Training epoch 2/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 2/50 | Train Acc: 0.833 | Val Acc: 0.239 | Best: 0.239\n",
            "Training epoch 3/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 3/50 | Train Acc: 0.902 | Val Acc: 0.280 | Best: 0.280\n",
            "Training epoch 4/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 4/50 | Train Acc: 0.933 | Val Acc: 0.301 | Best: 0.301\n",
            "Training epoch 5/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 5/50 | Train Acc: 0.951 | Val Acc: 0.301 | Best: 0.301\n",
            "Training epoch 6/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 6/50 | Train Acc: 0.963 | Val Acc: 0.289 | Best: 0.301\n",
            "Training epoch 7/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 7/50 | Train Acc: 0.971 | Val Acc: 0.291 | Best: 0.301\n",
            "Training epoch 8/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 8/50 | Train Acc: 0.977 | Val Acc: 0.276 | Best: 0.301\n",
            "Training epoch 9/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 9/50 | Train Acc: 0.981 | Val Acc: 0.270 | Best: 0.301\n",
            "Training epoch 10/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n",
            "Epoch 10/50 | Train Acc: 0.983 | Val Acc: 0.270 | Best: 0.301\n",
            "Training epoch 11/50\n",
            "M4 Pro GPU memory allocated: 0.02 GB\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m running_loss, correct, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     18\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(DEVICE), yb\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mAugmentedDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
            "File \u001b[0;32m~/Diploma/ecg_ml_analysis/v2/notebooks/../wfdb_parser.py:237\u001b[0m, in \u001b[0;36mWFDBECGDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(window\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 237\u001b[0m         window[:, ch] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_augment_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Pad channels if needed\u001b[39;00m\n\u001b[1;32m    240\u001b[0m n_pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_channels \u001b[38;5;241m-\u001b[39m window\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m~/Diploma/ecg_ml_analysis/v2/notebooks/../wfdb_parser.py:189\u001b[0m, in \u001b[0;36mWFDBECGDataset._augment_signal\u001b[0;34m(self, signal)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Random scaling\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.3\u001b[39m:\n\u001b[0;32m--> 189\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     signal \u001b[38;5;241m=\u001b[39m signal \u001b[38;5;241m*\u001b[39m scale\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Random time shift (circular shift)\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Advanced training with early stopping\n",
        "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "best_val_acc = 0\n",
        "patience = 20\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"\\nüéØ Training for {EPOCHS} epochs...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    # Training\n",
        "    print(f\"Training epoch {epoch}/{EPOCHS}\")\n",
        "    if DEVICE.type == \"mps\":\n",
        "        print(f\"M4 Pro GPU memory allocated: {torch.mps.current_allocated_memory() / 1024**3:.2f} GB\")\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    \n",
        "    train_losses.append(running_loss/total)\n",
        "    train_accs.append(correct/total)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    \n",
        "    val_losses.append(running_loss/total)\n",
        "    val_accs.append(correct/total)\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_accs[-1])\n",
        "    \n",
        "    # Early stopping\n",
        "    if val_accs[-1] > best_val_acc:\n",
        "        best_val_acc = val_accs[-1]\n",
        "        patience_counter = 0\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'best_model.pth'))\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    print(f\"Epoch {epoch}/{EPOCHS} | Train Acc: {train_accs[-1]:.3f} | Val Acc: {val_accs[-1]:.3f} | Best: {best_val_acc:.3f}\")\n",
        "    \n",
        "    if patience_counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best_model.pth')))\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Training completed in {training_time:.2f} seconds\")\n",
        "print(f\"üèÜ Best validation accuracy: {best_val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation\n",
        "\n",
        "Comprehensive evaluation with detailed metrics and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== COMPREHENSIVE EVALUATION ===\n",
            "Test Accuracy: 0.9994\n",
            "F1-Score (Macro): 0.9995\n",
            "F1-Score (Weighted): 0.9994\n",
            "\n",
            "Detailed Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Age_1.0     0.9991    1.0000    0.9996      2242\n",
            "     Age_2.0     0.9997    0.9993    0.9995     17409\n",
            "     Age_3.0     0.9991    0.9989    0.9990     10026\n",
            "     Age_4.0     0.9991    0.9998    0.9994      4453\n",
            "     Age_5.0     1.0000    0.9995    0.9998      2108\n",
            "     Age_6.0     0.9983    0.9991    0.9987      2315\n",
            "     Age_7.0     0.9987    1.0000    0.9994      2367\n",
            "     Age_8.0     0.9991    1.0000    0.9995      2167\n",
            "     Age_9.0     1.0000    1.0000    1.0000       697\n",
            "    Age_10.0     1.0000    1.0000    1.0000      1098\n",
            "    Age_11.0     1.0000    1.0000    1.0000       748\n",
            "    Age_12.0     1.0000    0.9958    0.9979       478\n",
            "    Age_13.0     1.0000    1.0000    1.0000       230\n",
            "    Age_14.0     1.0000    1.0000    1.0000       412\n",
            "    Age_15.0     1.0000    1.0000    1.0000       238\n",
            "\n",
            "    accuracy                         0.9994     46988\n",
            "   macro avg     0.9995    0.9995    0.9995     46988\n",
            "weighted avg     0.9994    0.9994    0.9994     46988\n",
            "\n",
            "‚úÖ Model evaluation completed\n"
          ]
        }
      ],
      "source": [
        "# Comprehensive evaluation\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "probs_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        out = model(xb)\n",
        "        probs = nn.functional.softmax(out, dim=1)\n",
        "        max_probs, _ = probs.max(1)\n",
        "        probs_list.append(max_probs.cpu().numpy())\n",
        "\n",
        "        preds = out.argmax(dim=1)\n",
        "        y_true.append(yb.cpu().numpy())\n",
        "        y_pred.append(preds.cpu().numpy())\n",
        "\n",
        "y_true = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)\n",
        "probs_all = np.concatenate(probs_list)\n",
        "\n",
        "# Comprehensive metrics\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\n=== COMPREHENSIVE EVALUATION ===\")\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, digits=4, target_names=[f'Age_{c}' for c in dataset.le.classes_]))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"‚úÖ Model evaluation completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization and Analysis\n",
        "\n",
        "Generate comprehensive visualizations for training analysis and model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Training analysis plot saved\n"
          ]
        }
      ],
      "source": [
        "# Generate comprehensive plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# 1) Training curves with learning rate\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes[0,0].plot(train_losses, label=\"Train Loss\")\n",
        "axes[0,0].plot(val_losses, label=\"Val Loss\")\n",
        "axes[0,0].set_xlabel(\"Epoch\"); axes[0,0].set_ylabel(\"Loss\")\n",
        "axes[0,0].set_title(\"Loss Curves\"); axes[0,0].legend(); axes[0,0].grid(True)\n",
        "\n",
        "axes[0,1].plot(train_accs, label=\"Train Acc\")\n",
        "axes[0,1].plot(val_accs, label=\"Val Acc\")\n",
        "axes[0,1].set_xlabel(\"Epoch\"); axes[0,1].set_ylabel(\"Accuracy\")\n",
        "axes[0,1].set_title(\"Accuracy Curves\"); axes[0,1].legend(); axes[0,1].grid(True)\n",
        "\n",
        "# Class distribution\n",
        "class_dist = Counter(y_true)\n",
        "axes[1,0].bar(range(len(class_dist)), list(class_dist.values()))\n",
        "axes[1,0].set_xlabel(\"Age Group\"); axes[1,0].set_ylabel(\"Count\")\n",
        "axes[1,0].set_title(\"Test Set Class Distribution\")\n",
        "axes[1,0].set_xticks(range(len(class_dist)))\n",
        "axes[1,0].set_xticklabels([f'Age_{c}' for c in sorted(class_dist.keys())], rotation=45)\n",
        "\n",
        "# Prediction confidence\n",
        "axes[1,1].hist(probs_all, bins=20, color=\"green\", alpha=0.7)\n",
        "axes[1,1].set_xlabel(\"Max Predicted Probability\")\n",
        "axes[1,1].set_ylabel(\"Count\")\n",
        "axes[1,1].set_title(\"Prediction Confidence Distribution\")\n",
        "axes[1,1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"training_analysis.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Training analysis plot saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Confusion matrix saved\n"
          ]
        }
      ],
      "source": [
        "# 2) Enhanced confusion matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[f'Age_{c}' for c in dataset.le.classes_], \n",
        "            yticklabels=[f'Age_{c}' for c in dataset.le.classes_])\n",
        "plt.xlabel(\"Predicted Age Group\"); plt.ylabel(\"True Age Group\")\n",
        "plt.title(f\"Confusion Matrix\\nAccuracy: {acc:.3f} | F1-Macro: {f1_macro:.3f} | F1-Weighted: {f1_weighted:.3f}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_matrix.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Confusion matrix saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Per-class performance analysis saved\n"
          ]
        }
      ],
      "source": [
        "# 3) Per-class performance analysis\n",
        "per_class_acc = []\n",
        "per_class_f1 = []\n",
        "for i in range(n_classes):\n",
        "    idx = (y_true == i)\n",
        "    if idx.any():\n",
        "        acc_i = (y_pred[idx] == y_true[idx]).mean()\n",
        "        # For multiclass, we need to use a different approach for per-class F1\n",
        "        # Create binary labels for this class vs all others\n",
        "        y_true_binary = (y_true == i).astype(int)\n",
        "        y_pred_binary = (y_pred == i).astype(int)\n",
        "        f1_i = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
        "    else:\n",
        "        acc_i = 0.0\n",
        "        f1_i = 0.0\n",
        "    per_class_acc.append(acc_i)\n",
        "    per_class_f1.append(f1_i)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "x_pos = range(len(dataset.le.classes_))\n",
        "ax1.bar(x_pos, per_class_acc, color=\"skyblue\", alpha=0.7)\n",
        "ax1.set_xlabel(\"Age Group\"); ax1.set_ylabel(\"Accuracy\")\n",
        "ax1.set_title(\"Per-class Accuracy\")\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels([f'Age_{c}' for c in dataset.le.classes_], rotation=45)\n",
        "ax1.grid(axis='y')\n",
        "\n",
        "ax2.bar(x_pos, per_class_f1, color=\"lightcoral\", alpha=0.7)\n",
        "ax2.set_xlabel(\"Age Group\"); ax2.set_ylabel(\"F1-Score\")\n",
        "ax2.set_title(\"Per-class F1-Score\")\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels([f'Age_{c}' for c in dataset.le.classes_], rotation=45)\n",
        "ax2.grid(axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"per_class_performance.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Per-class performance analysis saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Class imbalance analysis saved\n"
          ]
        }
      ],
      "source": [
        "# 4) Class imbalance analysis\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# True vs Predicted distribution\n",
        "ax1.hist(y_true, bins=len(dataset.le.classes_), alpha=0.7, label=\"True\", color=\"blue\")\n",
        "ax1.hist(y_pred, bins=len(dataset.le.classes_), alpha=0.7, label=\"Predicted\", color=\"red\")\n",
        "ax1.set_xlabel(\"Age Group\"); ax1.set_ylabel(\"Count\")\n",
        "ax1.set_title(\"True vs Predicted Distribution\")\n",
        "ax1.legend(); ax1.grid(True)\n",
        "\n",
        "# Class weights visualization\n",
        "class_weights_np = class_weights.cpu().numpy()\n",
        "ax2.bar(range(len(class_weights_np)), class_weights_np, color=\"orange\", alpha=0.7)\n",
        "ax2.set_xlabel(\"Age Group\"); ax2.set_ylabel(\"Class Weight\")\n",
        "ax2.set_title(\"Computed Class Weights\")\n",
        "ax2.set_xticks(range(len(dataset.le.classes_)))\n",
        "ax2.set_xticklabels([f'Age_{c}' for c in dataset.le.classes_], rotation=45)\n",
        "ax2.grid(axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"class_imbalance_analysis.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Class imbalance analysis saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Sample ECG predictions saved\n"
          ]
        }
      ],
      "source": [
        "# 5) Sample ECG signals with predictions\n",
        "plt.figure(figsize=(15, 10))\n",
        "sample_indices = np.random.choice(len(test_dataset), 6, replace=False)\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    xb, yb = test_dataset[idx]\n",
        "    xb_numpy = xb.cpu().numpy()  # Keep numpy version for plotting\n",
        "    y_true_sample = dataset.le.inverse_transform([yb.item()])[0]\n",
        "    with torch.no_grad():\n",
        "        # Use the original tensor for model inference\n",
        "        out = model(xb.unsqueeze(0).to(DEVICE))\n",
        "        pred_label = dataset.le.inverse_transform([out.argmax(1).item()])[0]\n",
        "        confidence = torch.softmax(out, dim=1).max().item()\n",
        "    \n",
        "    plt.subplot(3, 2, i+1)\n",
        "    plt.plot(xb_numpy.T, alpha=0.7)  # plot all channels\n",
        "    plt.title(f\"True: Age_{y_true_sample} | Pred: Age_{pred_label} | Conf: {confidence:.3f}\")\n",
        "    plt.xlabel(\"Time\"); plt.ylabel(\"Amplitude\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"sample_ecg_predictions.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Sample ECG predictions saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model summary saved\n",
            "\n",
            "üéâ CNN training completed!\n",
            "üìÅ Results saved to: ./ecg_cnn_outputs/\n",
            "üìä Generated files:\n",
            "  ‚Ä¢ training_analysis.png\n",
            "  ‚Ä¢ confusion_matrix.png\n",
            "  ‚Ä¢ per_class_performance.png\n",
            "  ‚Ä¢ class_imbalance_analysis.png\n",
            "  ‚Ä¢ sample_ecg_predictions.png\n",
            "  ‚Ä¢ model_summary.png\n",
            "  ‚Ä¢ best_model.pth\n",
            "\n",
            "üìà Final Metrics:\n",
            "  ‚Ä¢ Test Accuracy: 0.9994\n",
            "  ‚Ä¢ F1-Score (Macro): 0.9995\n",
            "  ‚Ä¢ F1-Score (Weighted): 0.9994\n",
            "  ‚Ä¢ Training time: 122635.35 seconds\n",
            "  ‚Ä¢ Total parameters: 486,975\n",
            "  ‚Ä¢ Best validation accuracy: 0.9996\n"
          ]
        }
      ],
      "source": [
        "# 6) Model architecture visualization\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.text(0.1, 0.9, \"Advanced CNN Architecture:\", fontsize=16, fontweight='bold')\n",
        "plt.text(0.1, 0.8, \"‚Ä¢ Residual Blocks with Skip Connections\", fontsize=12)\n",
        "plt.text(0.1, 0.75, \"‚Ä¢ Attention Mechanisms for Feature Selection\", fontsize=12)\n",
        "plt.text(0.1, 0.7, \"‚Ä¢ Batch Normalization and Dropout\", fontsize=12)\n",
        "plt.text(0.1, 0.65, \"‚Ä¢ Focal Loss for Class Imbalance\", fontsize=12)\n",
        "plt.text(0.1, 0.6, \"‚Ä¢ Weighted Random Sampling\", fontsize=12)\n",
        "plt.text(0.1, 0.55, \"‚Ä¢ Learning Rate Scheduling\", fontsize=12)\n",
        "plt.text(0.1, 0.5, \"‚Ä¢ Early Stopping\", fontsize=12)\n",
        "plt.text(0.1, 0.4, f\"Final Performance:\", fontsize=14, fontweight='bold')\n",
        "plt.text(0.1, 0.35, f\"‚Ä¢ Accuracy: {acc:.4f}\", fontsize=12)\n",
        "plt.text(0.1, 0.3, f\"‚Ä¢ F1-Macro: {f1_macro:.4f}\", fontsize=12)\n",
        "plt.text(0.1, 0.25, f\"‚Ä¢ F1-Weighted: {f1_weighted:.4f}\", fontsize=12)\n",
        "plt.text(0.1, 0.2, f\"‚Ä¢ Classes: {n_classes}\", fontsize=12)\n",
        "plt.text(0.1, 0.15, f\"‚Ä¢ Channels: {n_channels}\", fontsize=12)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"model_summary.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Model summary saved\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\nüéâ CNN training completed!\")\n",
        "print(f\"üìÅ Results saved to: {OUTPUT_DIR}/\")\n",
        "print(\"üìä Generated files:\")\n",
        "print(\"  ‚Ä¢ training_analysis.png\")\n",
        "print(\"  ‚Ä¢ confusion_matrix.png\")\n",
        "print(\"  ‚Ä¢ per_class_performance.png\")\n",
        "print(\"  ‚Ä¢ class_imbalance_analysis.png\")\n",
        "print(\"  ‚Ä¢ sample_ecg_predictions.png\")\n",
        "print(\"  ‚Ä¢ model_summary.png\")\n",
        "print(\"  ‚Ä¢ best_model.pth\")\n",
        "\n",
        "print(f\"\\nüìà Final Metrics:\")\n",
        "print(f\"  ‚Ä¢ Test Accuracy: {acc:.4f}\")\n",
        "print(f\"  ‚Ä¢ F1-Score (Macro): {f1_macro:.4f}\")\n",
        "print(f\"  ‚Ä¢ F1-Score (Weighted): {f1_weighted:.4f}\")\n",
        "print(f\"  ‚Ä¢ Training time: {training_time:.2f} seconds\")\n",
        "print(f\"  ‚Ä¢ Total parameters: {total_params:,}\")\n",
        "print(f\"  ‚Ä¢ Best validation accuracy: {best_val_acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
